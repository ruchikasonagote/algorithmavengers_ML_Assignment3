{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Train on MNIST dataset using an MLP. The original training dataset contains 60,000 images and test contains 10,000 images. If you are short on compute, use a stratified subset of a smaller number of images. But, the test set remains the same 10,000 images. Compare against RF and Logistic Regression models.  The metrics can be: F1-score, confusion matrix. What do you observe? What all digits are commonly confused?\n"
      ],
      "metadata": {
        "id": "qUiuT_0Repby"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "MLP"
      ],
      "metadata": {
        "id": "qlk-HBpFF6gY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt # for making figures\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "from pprint import pprint\n",
        "import numpy as np\n",
        "import os\n",
        "import struct\n",
        "from sklearn.metrics import rand_score\n",
        "from scipy.spatial.distance import cdist\n",
        "import time"
      ],
      "metadata": {
        "id": "h-4x7SSQ8ZBV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "d7WHdp178ZbV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_mnist_images(filename):\n",
        "    with open(filename, 'rb') as f:\n",
        "        magic, num, rows, cols = struct.unpack(\">IIII\", f.read(16))\n",
        "        images = np.fromfile(f, dtype=np.uint8).reshape(num, rows*cols)\n",
        "    return images\n",
        "\n",
        "def load_mnist_labels(filename):\n",
        "    with open(filename, 'rb') as f:\n",
        "        magic, num = struct.unpack(\">II\", f.read(8))\n",
        "        labels = np.fromfile(f, dtype=np.uint8)\n",
        "    return labels\n",
        "\n",
        "train_images_path = \"/content/train-images.idx3-ubyte\"\n",
        "train_labels_path = \"/content/train-labels.idx1-ubyte\"\n",
        "\n",
        "test_images_path = \"/content/t10k-images.idx3-ubyte\"\n",
        "test_labels_path = \"/content/t10k-labels.idx1-ubyte\"\n",
        "\n",
        "# Load the data\n",
        "train_images = load_mnist_images(train_images_path)\n",
        "train_labels = load_mnist_labels(train_labels_path)\n",
        "\n",
        "test_images = load_mnist_images(test_images_path)\n",
        "test_labels = load_mnist_labels(test_labels_path)\n",
        "\n",
        "np.random.seed(42)\n",
        "print(\"train_images: \")\n",
        "print(len(train_images))\n",
        "print(\"test_images: \")\n",
        "print(len(test_images))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gobF31t48hHn",
        "outputId": "ec1a9bc7-c710-43e2-948e-ce27b541a22c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_images: \n",
            "60000\n",
            "test_images: \n",
            "10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_size = train_images[0].shape\n",
        "image_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6YZvXd0u820k",
        "outputId": "6ed42db1-4ae2-4082-bb14-d1cfe76c638e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(784,)"
            ]
          },
          "metadata": {},
          "execution_count": 181
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NasT7NVD_pIV",
        "outputId": "4974f9e8-e409-44f4-f064-d167cc9a10ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_img = torch.tensor(train_images).to(device)"
      ],
      "metadata": {
        "id": "cFOSDp6c_s1i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "flattened_images = [img.view(-1) for img in X_img]\n",
        "# Stack all flattened images into a single matrix\n",
        "X = torch.stack(flattened_images)\n",
        "# shape (60000, 784)\n",
        "X = X.view(-1, 784)\n",
        "print(X.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rra3RBfE_u7H",
        "outputId": "121e35d8-53c6-406d-8193-0aad027c7430"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([60000, 784])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MyOBdydLANqP",
        "outputId": "2d778491-bb6a-432f-8034-2b0fdcc469a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 184
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "444EJW-k_wgk",
        "outputId": "77d77cd3-cf4c-4279-d47c-4eb48a5d7a0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000,)"
            ]
          },
          "metadata": {},
          "execution_count": 185
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y = torch.tensor(train_labels).to(device)\n",
        "\n"
      ],
      "metadata": {
        "id": "2HdclYI8_11P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = X.float()"
      ],
      "metadata": {
        "id": "dz0F0xS4Vq8A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = 784\n",
        "class predict_digit(nn.Module):\n",
        "    def __init__(self, l1, l2, l3, input_size):\n",
        "        super().__init__()\n",
        "        self.lin1 = nn.Linear(input_size, l1)\n",
        "        self.lin2 = nn.Linear(l1, l2)\n",
        "        self.lin3 = nn.Linear(l2, l3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.lin1(x))\n",
        "        x = torch.relu(self.lin2(x))\n",
        "        x = self.lin3(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "IGfGWIFm_4EB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = predict_digit(l1=30, l2=20, l3=10, input_size=784)"
      ],
      "metadata": {
        "id": "bBNCmr81_6Bu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y = Y.long()"
      ],
      "metadata": {
        "id": "2M5_dCfIA2qo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure the model is on the correct device\n",
        "model.to(device)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "opt = torch.optim.AdamW(model.parameters(), lr=0.01)\n",
        "# Mini-batch training\n",
        "batch_size = 6000\n",
        "print_every = 1000\n",
        "elapsed_time = []\n",
        "# Adjustments for training monitoring\n",
        "avg_loss_values = []  # To store average loss per epoch\n",
        "\n",
        "for epoch in range(10000):  # Assuming you still want a large number of epochs\n",
        "    start_time = time.time()\n",
        "    total_loss = 0\n",
        "    for i in range(0, X.shape[0], batch_size):\n",
        "        x_batch = X[i:i+batch_size].to(device).float()\n",
        "        y_batch = Y[i:i+batch_size].to(device).long()\n",
        "\n",
        "        # Forward pass\n",
        "        y_pred = model(x_batch)\n",
        "        loss = loss_fn(y_pred, y_batch)\n",
        "\n",
        "        # Backward pass and optimize\n",
        "        opt.zero_grad()\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "\n",
        "        total_loss += loss.item() * x_batch.size(0)\n",
        "\n",
        "    avg_loss = total_loss / X.shape[0]\n",
        "    avg_loss_values.append(avg_loss)\n",
        "\n",
        "    end_time = time.time()\n",
        "    elapsed_time.append(end_time - start_time)\n",
        "\n",
        "    if epoch % print_every == 0:\n",
        "        print(f\"Epoch [{epoch+1}/10000], Loss: {avg_loss:.4f}, Time: {elapsed_time[-1]:.2f}s\")\n",
        "\n",
        "# Save the model after training\n",
        "torch.save(model.state_dict(), 'model_path.pth')\n",
        "print(\"Model saved successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1NgLSdD5__bT",
        "outputId": "8104a033-d1ac-41ac-dc8f-95082a7ff797"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10000], Loss: 10.4484, Time: 0.02s\n",
            "Epoch [1001/10000], Loss: 0.2662, Time: 0.02s\n",
            "Epoch [2001/10000], Loss: 0.2408, Time: 0.02s\n",
            "Epoch [3001/10000], Loss: 0.2345, Time: 0.02s\n",
            "Epoch [4001/10000], Loss: 0.2389, Time: 0.02s\n",
            "Epoch [5001/10000], Loss: 0.2310, Time: 0.02s\n",
            "Epoch [6001/10000], Loss: 0.2217, Time: 0.02s\n",
            "Epoch [7001/10000], Loss: 0.2285, Time: 0.02s\n",
            "Epoch [8001/10000], Loss: 0.2342, Time: 0.02s\n",
            "Epoch [9001/10000], Loss: 0.2176, Time: 0.02s\n",
            "Model saved successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To show the predicted digit"
      ],
      "metadata": {
        "id": "EM3rI4LqCH04"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming the model's architecture is defined as predict_digit\n",
        "model = predict_digit(l1=30, l2=20, l3=10, input_size=784).to(device)\n",
        "model.load_state_dict(torch.load('model_path.pth'))\n",
        "model.eval()  # Set the model to evaluation mode"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ry9wA_HrAFte",
        "outputId": "3c747366-f051-41e2-f4f5-5bcab3f05ca0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "predict_digit(\n",
              "  (lin1): Linear(in_features=784, out_features=30, bias=True)\n",
              "  (lin2): Linear(in_features=30, out_features=20, bias=True)\n",
              "  (lin3): Linear(in_features=20, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 241
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assume train_images and train_labels are loaded similarly to your training data\n",
        "# Processing test data\n",
        "\n",
        "with torch.no_grad():  # No need to track gradients\n",
        "    outputs = model(X)\n",
        "    _, predicted_mlp_train = torch.max(outputs.data, 1)\n",
        "predicted_mlp_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4KEvBVIwTl99",
        "outputId": "c28346e7-6405-4b13-8e82-f485850de626"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 0, 4,  ..., 5, 6, 5], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assume test_images and test_labels are loaded similarly to your training data\n",
        "# Processing test data\n",
        "X_test = torch.tensor(test_images).float().to(device)\n",
        "X_test = X_test.view(-1, 784)  # Adjust shape as necessary\n",
        "# Assuming test labels are for evaluation of performance and not required for just predictions\n",
        "Y_test = torch.tensor(test_labels).to(device)\n",
        "\n",
        "with torch.no_grad():  # No need to track gradients\n",
        "    outputs = model(X_test)\n",
        "    _, predicted_mlp_test = torch.max(outputs.data, 1)\n",
        "predicted_mlp_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H4BUl_huDdeT",
        "outputId": "fcb57931-4b2a-4cb9-9c44-ec96ef555555"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([7, 2, 1,  ..., 4, 5, 6], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rr3oNcfOFAO-",
        "outputId": "09a3172e-1f58-4b30-a8c6-cb9496eb6185"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[7 2 1 ... 4 5 6]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uokbd_wCFDa0",
        "outputId": "4a7b2bb5-395f-47cc-ab97-23fd4cd62a55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([7.5700, 9.2421, 4.4415,  ..., 5.2707, 2.0860, 7.3614], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xevN2XC9FF2S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using RF"
      ],
      "metadata": {
        "id": "dr6VWIFFF_kM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install latexify"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CoB-W06RGMMa",
        "outputId": "d1c2b73e-c228-45e2-ede4-181b2dfad65c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement latexify (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for latexify\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import ListedColormap\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.datasets import make_moons, make_circles, make_classification\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from IPython.display import Image\n",
        "\n",
        "# To plot trees in forest via graphviz\n",
        "from sklearn.tree import export_graphviz\n",
        "import graphviz\n",
        "\n",
        "try:\n",
        "    from latexify import latexify, format_axes\n",
        "    latexify(columns=2)\n",
        "except:\n",
        "    pass\n",
        "\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format='retina'"
      ],
      "metadata": {
        "id": "caQwjNfUF_E2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = X.cpu()\n",
        "Y = Y.cpu()"
      ],
      "metadata": {
        "id": "7SzE149tHnSn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Divide dataset into X and y\n",
        "# X, y = iris.iloc[:, :-1], iris.iloc[:, -1]\n",
        "rf = RandomForestClassifier(n_estimators=10,random_state=0, criterion='entropy', bootstrap=True)\n",
        "rf.fit(X,Y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "BzdfVXC6GcFa",
        "outputId": "301dda8c-2957-461d-a2b9-3f7124d04b0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(criterion='entropy', n_estimators=10, random_state=0)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;, n_estimators=10, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;, n_estimators=10, random_state=0)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming new_images is your new data that's already loaded and preprocessed\n",
        "\n",
        "# Convert to tensor and reshape\n",
        "new_images_tensor = torch.tensor(test_images).to(device)\n",
        "new_flattened_images = [img.view(-1) for img in new_images_tensor]\n",
        "new_X = torch.stack(new_flattened_images)\n",
        "new_X = new_X.view(-1, 784)\n",
        "# Convert to NumPy for scikit-learn if it's not already\n",
        "new_X_np = new_X.cpu().numpy()\n",
        "\n",
        "# Predict the labels\n",
        "predicted_labels_rf = rf.predict(new_X_np)\n",
        "\n",
        "# Now, predicted_labels contains the predicted labels for your new images\n",
        "predicted_labels_rf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qz5F96x-GhP0",
        "outputId": "d263fc71-d304-420e-ce9c-813e1b954812"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([7, 2, 1, ..., 4, 5, 6], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict the labels\n",
        "predicted_labels_rf_train = rf.predict(X.cpu())\n",
        "\n",
        "# Now, predicted_labels contains the predicted labels for your new images\n",
        "predicted_labels_rf_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w4XqQuQ8IGBJ",
        "outputId": "253e7dc0-f6b8-472c-ff8a-a8c87c207f36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using Logistic Regression"
      ],
      "metadata": {
        "id": "2jttuqbtIHoH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install latexify"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r8iWVx6nIomn",
        "outputId": "40458976-4201-4bfd-8c5f-3373a429e28f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement latexify (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for latexify\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import sklearn\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "# from latexify import *\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'"
      ],
      "metadata": {
        "id": "-Fw-1PQgILn5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiClassLogisticRegression(nn.Module):\n",
        "    def __init__(self, input_dim, num_classes):\n",
        "        super(MultiClassLogisticRegression, self).__init__()\n",
        "        self.linear = nn.Linear(input_dim, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        logits = self.linear(x)\n",
        "        return logits"
      ],
      "metadata": {
        "id": "jowT38S_IjAO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "log_reg = MultiClassLogisticRegression(784,10)"
      ],
      "metadata": {
        "id": "30KVlMxFIu6U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = X.float()"
      ],
      "metadata": {
        "id": "UCr8bLr-LkLN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "log_reg(X).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UKyzdZv9LFTI",
        "outputId": "666fa7f9-775e-451c-bb8e-4ca2cbb948ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([60000, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "log_reg(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6mw6jlOSLtx5",
        "outputId": "fbb3014e-c24c-49e7-cd24-6971d81fb8b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 17.2993, -87.9405, -27.1262,  ...,  15.0434,  59.2862, -52.1852],\n",
              "        [ 21.8101, -28.3861,  -9.1615,  ..., -31.0196,  45.9597, -28.0943],\n",
              "        [-17.7398, -33.0451, -35.7391,  ...,  23.3972,  74.3131, -23.6910],\n",
              "        ...,\n",
              "        [ 45.6391,  -8.3765, -84.7892,  ..., -47.1744,  26.6075,  17.2581],\n",
              "        [ -6.5541,   3.4983, -46.9361,  ...,   9.8314,  13.4657,  -0.2126],\n",
              "        [-13.3707, -40.9609, -64.4137,  ...,   4.2377,  89.3492,  14.8161]],\n",
              "       grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "opt = torch.optim.Adam(log_reg.parameters(), lr=0.01)\n",
        "\n",
        "converged = False\n",
        "prev_loss = 1e8\n",
        "\n",
        "i = 0\n",
        "while not converged:\n",
        "    opt.zero_grad()\n",
        "    logits = log_reg(X)\n",
        "    loss = F.cross_entropy(logits, Y)\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "    if i%10000==0:\n",
        "        print(i, loss.item())\n",
        "    if np.abs(prev_loss - loss.item()) < 1e-5:\n",
        "        converged = True\n",
        "    prev_loss = loss.item()\n",
        "    i = i + 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZxLwmZsgJNEn",
        "outputId": "e49c6842-e9e4-4cb6-db7f-b69683a733d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 14.337325096130371\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To show predicted values"
      ],
      "metadata": {
        "id": "LXZL186oNSN7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy\n",
        "pred = F.softmax(log_reg(X.float().cpu()), dim=-1).detach().numpy()\n",
        "y_pred_train_logreg = pred.argmax(axis=-1)\n",
        "# (y_pred == Y).mean()"
      ],
      "metadata": {
        "id": "sQwWf8kgJ4qA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X_test = torch.tensor(test_images).float()\n",
        "X_test = X_test.view(-1, 784)  # Adjust shape as necessary\n",
        "# Assuming test labels are for evaluation of performance and not required for just predictions\n",
        "#Y_test = torch.tensor(test_labels).to(device)\n",
        "\n",
        "# Pass test images through the model to get logits\n",
        "logits = log_reg(X_test)\n",
        "\n",
        "# Apply softmax to obtain probabilities\n",
        "probabilities = F.softmax(logits, dim=1)\n",
        "\n",
        "# Get predicted classes (class with highest probability)\n",
        "predicted_classes_logreg = torch.argmax(probabilities, dim=1)\n",
        "\n",
        "# Print predicted classes\n",
        "print(\"Predicted classes:\", predicted_classes_logreg)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3API0Y4rNoIZ",
        "outputId": "d3c9063f-0c52-4923-f4a7-e13b0361858d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted classes: tensor([7, 2, 1,  ..., 4, 5, 6])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_labels_logreg_train\n"
      ],
      "metadata": {
        "id": "vaHoDfX-QH08"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score, confusion_matrix"
      ],
      "metadata": {
        "id": "6bUs1CFzTDhn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "F1 Score and Confusion Matrix of MLP"
      ],
      "metadata": {
        "id": "lXJMm4yRRLQR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#For Training Data\n",
        "\n",
        "# Example true labels and predicted labels (replace with your own data)\n",
        "true_labels = Y.cpu().numpy()\n",
        "predicted_labels = predicted_mlp_train.cpu().numpy()\n",
        "\n",
        "# Calculate F1-score\n",
        "f1_mlp_train = f1_score(true_labels, predicted_labels,average='weighted')\n",
        "\n",
        "# Create confusion matrix\n",
        "cm_mlp_train = confusion_matrix(true_labels, predicted_labels)\n",
        "\n",
        "print(f\"F1-score: {f1_mlp_train:.4f}\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm_mlp_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1wEkCIlQShS5",
        "outputId": "fe667ff7-dcf6-4369-948e-d1470c4ec898"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1-score: 0.8386\n",
            "Confusion Matrix:\n",
            "[[5225    2   89  109   20  180  248    9   30   11]\n",
            " [   9 6366  138    8    9   12   24   13  125   38]\n",
            " [  99  109 4742  433   70   17   82  141  222   43]\n",
            " [  76   43  948 4193    8  268   37  159  351   48]\n",
            " [  16   12    8    8 5257   70   75  195   40  161]\n",
            " [ 133    8   75  360   79 4206  151   16  294   99]\n",
            " [  47    9   37   10   68  213 5441    5   86    2]\n",
            " [  10   61   86    8  142    2    8 5646   10  292]\n",
            " [  19  384  147  159   68  300   46   30 4645   53]\n",
            " [  31  104    7   61  717   70    2  225   78 4654]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For Test Data\n",
        "\n",
        "# Example true labels and predicted labels (replace with your own data)\n",
        "true_labels = Y_test.cpu().numpy()\n",
        "predicted_labels = predicted_mlp_test.cpu().numpy()\n",
        "\n",
        "# Calculate F1-score\n",
        "f1_mlp_test = f1_score(true_labels, predicted_labels,average='weighted')\n",
        "\n",
        "# Create confusion matrix\n",
        "cm_mlp_test = confusion_matrix(true_labels, predicted_labels)\n",
        "\n",
        "print(f\"F1-score: {f1_mlp_test:.4f}\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm_mlp_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qfAETKgoRPRG",
        "outputId": "57d42047-aa0d-4bc8-aaae-e81b702b3043"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1-score: 0.8281\n",
            "Confusion Matrix:\n",
            "[[ 875    0   11   13    3   18   53    3    2    2]\n",
            " [   3 1091   13    2    1    1    3    2   15    4]\n",
            " [  20    9  830   77    9    2   10   24   38   13]\n",
            " [  18    4  151  697    1   46    4   23   58    8]\n",
            " [   2    2    3    1  880   11   13   34    9   27]\n",
            " [  23    3   13   85   22  646   17    7   57   19]\n",
            " [   8    3    2    3    9   38  880    3   11    1]\n",
            " [   2   15   31    6   23    0    2  898    1   50]\n",
            " [   7   53   23   32   28   58    8   13  744    8]\n",
            " [   6   32    1   13  148   14    1   31    9  754]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "F1 Score and Confusion Matrix of RF"
      ],
      "metadata": {
        "id": "4AvLF4QQWl4I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For train Data\n",
        "\n",
        "# Example true labels and predicted labels (replace with your own data)\n",
        "true_labels = Y.cpu().numpy()\n",
        "predicted_labels = predicted_labels_rf_train\n",
        "\n",
        "# Calculate F1-score\n",
        "f1_rf_train = f1_score(true_labels, predicted_labels,average='weighted')\n",
        "\n",
        "# Create confusion matrix\n",
        "cm_rf_train = confusion_matrix(true_labels, predicted_labels)\n",
        "\n",
        "print(f\"F1-score: {f1_rf_train:.4f}\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm_rf_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QzMUmmeRX4Mx",
        "outputId": "137adc5d-a5b1-4f60-f751-11a00bc73e4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1-score: 0.9992\n",
            "Confusion Matrix:\n",
            "[[5923    0    0    0    0    0    0    0    0    0]\n",
            " [   0 6741    0    0    0    0    0    1    0    0]\n",
            " [   0    0 5956    1    1    0    0    0    0    0]\n",
            " [   0    0    2 6122    0    1    0    3    2    1]\n",
            " [   0    0    0    0 5840    0    0    0    0    2]\n",
            " [   1    1    0    4    0 5414    1    0    0    0]\n",
            " [   3    1    0    0    0    1 5913    0    0    0]\n",
            " [   0    0    3    0    0    0    0 6261    0    1]\n",
            " [   0    1    0    1    0    1    2    1 5845    0]\n",
            " [   0    0    1    3    3    3    0    1    3 5935]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For Test Data\n",
        "\n",
        "# Example true labels and predicted labels (replace with your own data)\n",
        "true_labels = Y_test.cpu().numpy()\n",
        "predicted_labels = predicted_labels_rf\n",
        "\n",
        "# Calculate F1-score\n",
        "f1_rf_test = f1_score(true_labels, predicted_labels,average='weighted')\n",
        "\n",
        "# Create confusion matrix\n",
        "cm_rf_test = confusion_matrix(true_labels, predicted_labels)\n",
        "\n",
        "print(f\"F1-score: {f1_rf_test:.4f}\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm_rf_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "brYGbTp_YnvZ",
        "outputId": "3d196f1b-0355-422d-d2c5-6dd516920404"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1-score: 0.9522\n",
            "Confusion Matrix:\n",
            "[[ 968    1    1    0    0    2    5    1    1    1]\n",
            " [   0 1123    1    6    0    2    1    2    0    0]\n",
            " [   8    1  987    5    4    0    6   11   10    0]\n",
            " [   1    1   15  950    0   22    0   13    6    2]\n",
            " [   2    1    5    1  937    0    6    3    8   19]\n",
            " [   9    0    6   24    2  829    7    2   10    3]\n",
            " [  13    4    2    0    7    7  924    0    0    1]\n",
            " [   2    9   19    4    7    0    1  965    4   17]\n",
            " [   7    2    7   15    5   17    6    4  900   11]\n",
            " [   8    6    4   13   21    5    3    3    6  940]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LOg reg"
      ],
      "metadata": {
        "id": "M3TjpY5MYJbQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For train Data\n",
        "\n",
        "true_labels = Y.cpu().numpy()\n",
        "predicted_labels = y_pred_train_logreg\n",
        "\n",
        "# Calculate F1-score\n",
        "f1_logreg_train = f1_score(true_labels, predicted_labels,average='weighted')\n",
        "\n",
        "# Create confusion matrix\n",
        "cm_logreg_train = confusion_matrix(true_labels, predicted_labels)\n",
        "\n",
        "print(f\"F1-score: {f1_logreg_train:.4f}\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm_logreg_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u9YK_T8BYOoj",
        "outputId": "730cd92c-7a72-4209-80fa-3277b6fdede4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1-score: 0.9288\n",
            "Confusion Matrix:\n",
            "[[5764    0   30    2    5   43   21    4   48    6]\n",
            " [   1 6576   51   14    8   16    4    7   56    9]\n",
            " [  26   36 5564   30   47   34   46   37  116   22]\n",
            " [  31   32  238 4998   10  388   14   63  285   72]\n",
            " [  13   16   40    6 5485   17   36   23   41  165]\n",
            " [  35   10   47   54   42 4965   45    9  174   40]\n",
            " [  30    9   60    4   34   65 5675    0   40    1]\n",
            " [   8   13   59   11   53    9    2 5859   27  224]\n",
            " [  31   60  108   48   18  158   30   15 5325   58]\n",
            " [  13   13   17   19  141   49    1  111   66 5519]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For Test Data\n",
        "\n",
        "# Example true labels and predicted labels (replace with your own data)\n",
        "true_labels = Y_test.cpu().numpy()\n",
        "predicted_labels = predicted_classes_logreg\n",
        "\n",
        "# Calculate F1-score\n",
        "f1_logreg_test = f1_score(true_labels, predicted_labels,average='weighted')\n",
        "\n",
        "# Create confusion matrix\n",
        "cm_logreg_test = confusion_matrix(true_labels, predicted_labels)\n",
        "\n",
        "print(f\"F1-score: {f1_logreg_test:.4f}\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm_logreg_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eLIY0INgXPkb",
        "outputId": "7b782a37-a224-4b16-c6c5-4bb46506a7b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1-score: 0.8986\n",
            "Confusion Matrix:\n",
            "[[ 943    0    6    1    3   11    7    2    7    0]\n",
            " [   0 1095   11    3    1    2    3    3   16    1]\n",
            " [   7   13  903   17   10   10   19    8   39    6]\n",
            " [   7    5   43  817    5   62    3   13   43   12]\n",
            " [   1    4   12    4  900    2    7   14    9   29]\n",
            " [  11    3    8   17    7  770   19    5   39   13]\n",
            " [  10    3   15    4    6   21  894    0    5    0]\n",
            " [   1    6   27    9   11    2    0  922    7   43]\n",
            " [  10   17   13   16    9   31   14   10  841   13]\n",
            " [   3    7    3    6   27   10    1   31   19  902]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "nTqzXjLyXZ8c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Sf-DrOohe00z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o-ipWyDXe0ul"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us assume your MLP has 30 neurons in first layer, 20 in second layer and then 10 finally for the output layer (corresponding to 10 classes). On the trained MLP, plot the t-SNE for the output from the layer containing 20 neurons for the 10 digits. Contrast this with the t-SNE for the same layer but for an untrained model. What do you conclude?"
      ],
      "metadata": {
        "id": "vJwXeUtye2va"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rEwkzBfSe8IO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pFSpMRose809"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rgQnznMqe8rf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, use the trained MLP to predict on the Fashion-MNIST dataset. What do you observe? How do the embeddings (t-SNE viz for the second layer compare for MNIST and Fashion-MNIST images)"
      ],
      "metadata": {
        "id": "TTX8u3COe9Xn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# Load the CSV files\n",
        "train_df = pd.read_csv('/content/fashion-mnist_train.csv')\n",
        "test_df = pd.read_csv('/content/fashion-mnist_test.csv')\n",
        "\n",
        "# Separate features and labels\n",
        "X_train, y_train = train_df.drop('label', axis=1).values, train_df['label'].values\n",
        "X_test, y_test = test_df.drop('label', axis=1).values, test_df['label'].values\n",
        "\n",
        "# Convert data to PyTorch tensors\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
        "\n",
        "# Create PyTorch DataLoader\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n"
      ],
      "metadata": {
        "id": "PuCFbWsEfB61"
      },
      "execution_count": 264,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_tensor.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ljnI-eotnTBp",
        "outputId": "8f061980-de9e-430b-bb02-ff4de9dd941f"
      },
      "execution_count": 265,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([60000, 784])"
            ]
          },
          "metadata": {},
          "execution_count": 265
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_tensor.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGxqYNeBoRV7",
        "outputId": "feccf7a9-cc35-4cc4-c32c-11f7ea60a1b7"
      },
      "execution_count": 266,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10000, 784])"
            ]
          },
          "metadata": {},
          "execution_count": 266
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_f = X_train_tensor.to(device)"
      ],
      "metadata": {
        "id": "2ANigWF_otG8"
      },
      "execution_count": 267,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "flattened_images = [img.view(-1) for img in X_train_f]\n",
        "# Stack all flattened images into a single matrix\n",
        "X = torch.stack(flattened_images)\n",
        "# shape (60000, 784)\n",
        "X = X.view(-1, 784)\n",
        "X_train_f = X\n",
        "print(X_train_f.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQyzhU8eposT",
        "outputId": "59e206eb-a511-45dd-9efe-691d501784a9"
      },
      "execution_count": 268,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([60000, 784])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_f = y_train_tensor.to(device)"
      ],
      "metadata": {
        "id": "p2qHJ4kyp4jj"
      },
      "execution_count": 269,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_f.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6hz4Ku_qAqX",
        "outputId": "f36c9695-69c1-4761-db13-1ba2b0db455f"
      },
      "execution_count": 270,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([60000])"
            ]
          },
          "metadata": {},
          "execution_count": 270
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_f = X_train_f.float()\n",
        "y_train_f = y_train_f.long()"
      ],
      "metadata": {
        "id": "MOUm3ZRtqJ6k"
      },
      "execution_count": 271,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assume train_images and train_labels are loaded similarly to your training data\n",
        "# Processing test data\n",
        "\n",
        "with torch.no_grad():  # No need to track gradients\n",
        "    outputs = model(X_train_f)\n",
        "    _, predicted_mlp_train_f = torch.max(outputs.data, 1)\n",
        "predicted_mlp_train_f"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFsH3xUMsI8h",
        "outputId": "4f644a94-69c0-419c-f306-2ae5f0d1b2c8"
      },
      "execution_count": 272,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 6,  ..., 9, 1, 1], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 272
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_f"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "evTxWb-msQ2W",
        "outputId": "3c54c833-cf53-4e9a-a193-31b40861b0b7"
      },
      "execution_count": 273,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2, 9, 6,  ..., 8, 8, 7], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 273
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "foV-6Zryvucu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_tensor.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hRqpO3xh0GOl",
        "outputId": "e419b4e3-4154-4fdd-9c04-673705c16419"
      },
      "execution_count": 275,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10000, 784])"
            ]
          },
          "metadata": {},
          "execution_count": 275
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_f = X_test_tensor.to(device)"
      ],
      "metadata": {
        "id": "r-MGe0PjvJpD"
      },
      "execution_count": 276,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_f.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DtnNSpMBy3e6",
        "outputId": "9f9acd63-ca80-40c5-f417-42f72d30066b"
      },
      "execution_count": 277,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10000, 784])"
            ]
          },
          "metadata": {},
          "execution_count": 277
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "flattened_images = [img.view(-1) for img in X_test_f]\n",
        "# Stack all flattened images into a single matrix\n",
        "X = torch.stack(flattened_images)\n",
        "# shape (60000, 784)\n",
        "X = X.view(-1, 784)\n",
        "X_test_f = X\n",
        "print(X_test_f.shape)\n"
      ],
      "metadata": {
        "id": "QJ7J2MyZsf2n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d566b58b-b0d5-47ce-dcf7-629965d09ad8"
      },
      "execution_count": 278,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([10000, 784])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():  # No need to track gradients\n",
        "    outputs = model(X_test_f.float())\n",
        "    _, predicted_mlp_test_f = torch.max(outputs.data, 1)\n",
        "predicted_mlp_test_f"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RqXdWdo70QGb",
        "outputId": "4f693694-fc7b-4a66-f02d-6be892f77a9b"
      },
      "execution_count": 279,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([6, 6, 6,  ..., 2, 6, 6], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 279
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_mlp_test_f.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qmjPY1kOysz4",
        "outputId": "aff144dd-47eb-4370-eff2-e0575c44e097"
      },
      "execution_count": 280,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10000])"
            ]
          },
          "metadata": {},
          "execution_count": 280
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_f = y_test_tensor\n",
        "y_test_f = y_test_f.to(device)"
      ],
      "metadata": {
        "id": "bYPICMoDwk6w"
      },
      "execution_count": 284,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_f.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SdYUHQld0XaF",
        "outputId": "4f966afe-59c1-4716-e0c6-22dc9a7ecb9a"
      },
      "execution_count": 285,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10000])"
            ]
          },
          "metadata": {},
          "execution_count": 285
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_f"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQ55WlKi0vrg",
        "outputId": "9daf6416-65ea-4006-b443-49cab3252536"
      },
      "execution_count": 286,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 1, 2,  ..., 8, 8, 1], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 286
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Confusion matrix for Fashion MNIST"
      ],
      "metadata": {
        "id": "qg8ATWdnxOQr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For train Data\n",
        "\n",
        "true_labels = y_train_f.cpu().numpy()\n",
        "predicted_labels = predicted_mlp_train_f.cpu()\n",
        "\n",
        "# Calculate F1-score\n",
        "f1_mlp_train_f = f1_score(true_labels, predicted_labels,average='weighted')\n",
        "\n",
        "# Create confusion matrix\n",
        "cm_mlp_train_f = confusion_matrix(true_labels, predicted_labels)\n",
        "\n",
        "print(f\"F1-score: {f1_mlp_train_f:.4f}\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm_mlp_train_f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "juVRwdfrw4g9",
        "outputId": "14861f7e-903a-41b4-c19d-a8b2f7723059"
      },
      "execution_count": 255,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1-score: 0.0987\n",
            "Confusion Matrix:\n",
            "[[602 704 617 557 541 517 626 616 612 608]\n",
            " [585 711 622 574 564 488 601 655 588 612]\n",
            " [595 691 620 604 562 515 588 621 590 614]\n",
            " [584 734 600 562 555 546 618 655 547 599]\n",
            " [565 734 639 567 580 474 613 656 559 613]\n",
            " [602 736 595 548 605 477 591 660 551 635]\n",
            " [591 687 627 562 553 464 637 662 567 650]\n",
            " [646 736 588 606 569 480 578 607 571 619]\n",
            " [551 723 628 614 581 457 585 700 536 625]\n",
            " [629 748 601 574 566 493 597 612 574 606]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For test Data\n",
        "\n",
        "true_labels = y_test_f.cpu().numpy()\n",
        "predicted_labels = predicted_mlp_test_f.cpu()\n",
        "\n",
        "# Calculate F1-score\n",
        "f1_mlp_test_f = f1_score(true_labels, predicted_labels,average='weighted')\n",
        "\n",
        "# Create confusion matrix\n",
        "cm_mlp_test_f = confusion_matrix(true_labels, predicted_labels)\n",
        "\n",
        "print(f\"F1-score: {f1_mlp_test_f:.4f}\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm_mlp_test_f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84JkRqDkxvlr",
        "outputId": "f2e4d518-e753-495c-f0fe-cb3543a58dbe"
      },
      "execution_count": 287,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1-score: 0.0391\n",
            "Confusion Matrix:\n",
            "[[  1  38  73   1   0   0 867   3   1  16]\n",
            " [  0  68  85   0   0   0 847   0   0   0]\n",
            " [  2  22  17   0   0   8 949   1   0   1]\n",
            " [  0  48 176   0   0   1 760   4   0  11]\n",
            " [  0  26  46   5   0  29 894   0   0   0]\n",
            " [  2 314 491  40   2   0  89  32  27   3]\n",
            " [  1  62  53   3   0   6 868   0   1   6]\n",
            " [  0 681 309   1   0   0   0   8   1   0]\n",
            " [  3 359 206  87   2  17 220  11  27  68]\n",
            " [  0 216 602  92   0   0  85   0   5   0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NvkdRf_KyUe6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}